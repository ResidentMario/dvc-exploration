{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some local experiments to verify the proposal in the DVC Integration PDD will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using DVC locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ResidentMario/dvc-exploration` (e.g. this repo) is a GH repo containing a `data/` root directory with the files `train.csv.dvc`, `test.csv.dvc`, and `train_head.csv.dvc`.\n",
    "\n",
    "These files were generated by downloading the MNIST dataset from the [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer/data?select=test.csv) competition on Kaggle and unzipping the `train.csv` and `test.csv` files into this directory. Then running the following:\n",
    "\n",
    "```\n",
    "dvc init\n",
    "dvc add data/train.csv\n",
    "dvc add data/test.csv\n",
    "cd data\n",
    "dvc run -d train.csv -o train_head.csv \"head train.csv > train_head.csv\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commands two and three:\n",
    "1. Makes a content addressable copy of the file in `.dvc/cache`.\n",
    "2. Creates a `FILENAME.EXTENSION.dvc` file locally, e.g., `train.csv.dvc`. This is DVC metadata, the most important field of which is the `md5` hash.\n",
    "3. Creates or appends to a `.gitignore` in the directory telling `git` to ignore the data files.\n",
    "\n",
    "The contents of `train.csv.dvc` as an example:\n",
    "\n",
    "```yaml\n",
    "md5: f1fe550396d7b876a101ff449eced674\n",
    "outs:\n",
    "- md5: f3eaeafb90cde88b238ebc8dfd4501c5\n",
    "  path: train.csv\n",
    "  cache: true\n",
    "  metric: false\n",
    "  persist: false\n",
    "```\n",
    "\n",
    "The last command:\n",
    "1. Creates a new pipeline definition metadata file, `train_head.csv.dvc`. This contains `md5` hashes for both the input and output files.\n",
    "\n",
    "The contents of `train_head.csv.dvc`:\n",
    "\n",
    "```yaml\n",
    "md5: 0e1ce87d933511bce02403cd3d0ac8a8\n",
    "cmd: head train.csv > train_head.csv\n",
    "deps:\n",
    "- md5: f3eaeafb90cde88b238ebc8dfd4501c5\n",
    "  path: train.csv\n",
    "outs:\n",
    "- md5: e502cb16c02f3572bb68adadcfc50463\n",
    "  path: train_head.csv\n",
    "  cache: true\n",
    "  metric: false\n",
    "  persist: false\n",
    "```\n",
    "\n",
    "The content cache is in `FIRST_TWO_HASH_VALUES/REMAINING_VALUES` format:\n",
    "\n",
    "```\n",
    "$ ls .dvc/cache/\n",
    "a3 e5 f3\n",
    "$ ls a3\n",
    "5759d77c0a3dadb4d4253ff87ec430\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running these commands we have a repository with code managed by Git and data managed by DVC. So far so good, but it's still not reproducible (or very useful) because the repository is non-portable. The `.cache` directory is added to `.gitignore` at `dvc init` time; it's just a convenience for the targetting reuse of data files on local disk.\n",
    "\n",
    "## Using DVC with a remote\n",
    "\n",
    "To get utility out of DVC you need to configure a remote. This will allow you to `dvc push` to and `dvc pull` from the remote to get all of the data artifacts you need. DVC supports all of S3, GCS, and Azure Blob Storage.\n",
    "\n",
    "Run:\n",
    "\n",
    "```\n",
    "$ dvc remote add -d s3://spell-share/aleksey/dvc-exploration\n",
    "```\n",
    "\n",
    "This will configure this bucket and path as the default remote for this project. This is controlled by `.dvc/config`, a (`git` version controlled) file which is empty at `dvc init` time but whose contents will now be:\n",
    "\n",
    "```ini\n",
    "[core]\n",
    "    remote = spell-share\n",
    "['remote \"spell-share\"']\n",
    "    url = s3://spell-share/aleksey/dvc-exploration\n",
    "```\n",
    "\n",
    "To publish the data to collaborators you now:\n",
    "\n",
    "```\n",
    "$ dvc push\n",
    "```\n",
    "\n",
    "This flushes the contents of the `.dvc/cache` directory to S3:\n",
    "\n",
    "```\n",
    "$ aws s3 ls s3://spell-share/aleksey/dvc-exploration/\n",
    "                           PRE a3/\n",
    "                           PRE e5/\n",
    "                           PRE f3/\n",
    "```\n",
    "\n",
    "We can now reproduce the data for the repository from a clean copy of the repository:\n",
    "\n",
    "```\n",
    "$ git clone https://github.com/ResidentMario/dvc-exploration.git dvc-exploration-new\n",
    "$ cd dvc-exploration-new\n",
    "$ dvc pull\n",
    "```\n",
    "\n",
    "AFAICT this will find all of the `*.dvc` files rooted in the current directory (recursive search?), grab their `md5` fields, and `boto3` to pull them from the S3 CAS created in the `dvc push` step.\n",
    "\n",
    "This unifies all of your team's data fetch operations across all of your projects under a common API, which is very nice indeed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if you already have it in your local cache though\n",
    "\n",
    "Key observation: **DVC will skip pulling data from S3 if the file is already in the local cache**.\n",
    "\n",
    "To verify this, try the following:\n",
    "\n",
    "```\n",
    "$ cd ..; rm dc-exploration-new\n",
    "$ git clone https://github.com/ResidentMario/dvc-exploration.git dvc-exploration-new\n",
    "$ cd dvc-exploration-new\n",
    "$ cp -rf ../dvc-exploration/.dvc/cache .dvc/\n",
    "```\n",
    "\n",
    "This will make a copy of a complete local cache in the new repo without one.\n",
    "\n",
    "Then running again:\n",
    "\n",
    "```\n",
    "$ dvc pull\n",
    "```\n",
    "\n",
    "We skip all downloads.\n",
    "\n",
    "```\n",
    "3 added\n",
    "Everything is up to date.\n",
    "```\n",
    "\n",
    "So if you have a `.cache` directory with everything you need already defined, it's a no-op. If you have a `.cache` directory with some of the things you need already defined, it's less work and waiting you have to do pulling things over the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if you symlink the files to someplace else?\n",
    "\n",
    "Key observation: **DVC still works fine when the local cache files are symlinked to somewhere else on disk**.\n",
    "\n",
    "I created a `dvc-data-files` directory on my `Desktop` and moved the files included in the cache directory to there.\n",
    "\n",
    "```\n",
    "$ mkdir ~/Desktop/dvc-data-files/f3/\n",
    "$ mv f3/eaeafb90cde88b238ebc8dfd4501c5 ~/Desktop/dvc-data-files/f3/eaeafb90cde88b238ebc8dfd4501c5\n",
    "$ mkdir ~/Desktop/dvc-data-files/a3/\n",
    "$ mv a3/5759d77c0a3dadb4d4253ff87ec430 ~/Desktop/dvc-data-files/a3/5759d77c0a3dadb4d4253ff87ec430\n",
    "$ mkdir ~/Desktop/dvc-data-files/e5/\n",
    "$ mv e5/02cb16c02f3572bb68adadcfc50463 ~/Desktop/dvc-data-files/e5/02cb16c02f3572bb68adadcfc50463\n",
    "```\n",
    "\n",
    "Then, replacing the original files with symlinks to the new file locations:\n",
    "\n",
    "```\n",
    "$ ln -sf /Users/alekseybilogur/Desktop/dvc-data-files/e5/02cb16c02f3572bb68adadcfc50463 e5/02cb16c02f3572bb68adadcfc50463\n",
    "$ ln -sf /Users/alekseybilogur/Desktop/dvc-data-files/a3/5759d77c0a3dadb4d4253ff87ec430 a3/5759d77c0a3dadb4d4253ff87ec430\n",
    "$ ln -sf /Users/alekseybilogur/Desktop/dvc-data-files/f3/eaeafb90cde88b238ebc8dfd4501c5 f3/eaeafb90cde88b238ebc8dfd4501c5\n",
    "```\n",
    "\n",
    "The cache entries have all been replaced with symlinks to files located somewhere else on disk. Does the cache still work?\n",
    "\n",
    "```\n",
    "$ dvc pull\n",
    "No changes.\n",
    "Everything is up to date.\n",
    "```\n",
    "\n",
    "```\n",
    "dvc add train.csv\n",
    "Stage is cached, skipping.\n",
    "  0% Add|                                                                                      |0/0 [00:00,     ?file/s]\n",
    "```\n",
    "\n",
    "Looks like it does!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic idea of how this would work on Spell\n",
    "\n",
    "Spell users mount code into the environment using our `git` and `--github-url` integrations, and they mount data into the environment using the `--mount` flag.\n",
    "\n",
    "What if we inspected the git repo, looking for a `.dvc` file in the root of the directory. If it exists, we can look at the `config` file to determine if a remote is configured.\n",
    "\n",
    "If it is, and the user has mounted files from that remote into the run, we're in business! Crawl the repo for `*.dvc` files, extract the CAS addresses of those files. and subset that list to just those files included in the user mounts. Create the `.dvc/cache` directory and populate it with symlinks to the mount paths inside of the run. Place those files ahead of all other files in the goofyscache pull order, so that they get downloaded and added into the image ahead of everything else."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
