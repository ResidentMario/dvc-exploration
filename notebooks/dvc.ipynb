{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some local experiments to verify the proposal in the DVC Integration PDD will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using DVC locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ResidentMario/dvc-exploration` (e.g. this repo) is a GH repo containing a `data/` root directory with the files `train.csv.dvc`, `test.csv.dvc`, and `train_head.csv.dvc`.\n",
    "\n",
    "These files were generated by downloading the MNIST dataset from the [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer/data?select=test.csv) competition on Kaggle and unzipping the `train.csv` and `test.csv` files into this directory. Then running the following:\n",
    "\n",
    "```\n",
    "dvc init\n",
    "dvc add data/train.csv\n",
    "dvc add data/test.csv\n",
    "cd data\n",
    "dvc run -d train.csv -o train_head.csv \"head train.csv > train_head.csv\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commands two and three:\n",
    "1. Makes a content addressable copy of the file in `.dvc/cache`.\n",
    "2. Creates a `FILENAME.EXTENSION.dvc` file locally, e.g., `train.csv.dvc`. This is DVC metadata, the most important field of which is the `md5` hash.\n",
    "3. Creates or appends to a `.gitignore` in the directory telling `git` to ignore the data files.\n",
    "\n",
    "The contents of `train.csv.dvc` as an example:\n",
    "\n",
    "```yaml\n",
    "md5: f1fe550396d7b876a101ff449eced674\n",
    "outs:\n",
    "- md5: f3eaeafb90cde88b238ebc8dfd4501c5\n",
    "  path: train.csv\n",
    "  cache: true\n",
    "  metric: false\n",
    "  persist: false\n",
    "```\n",
    "\n",
    "The last command:\n",
    "1. Creates a new pipeline definition metadata file, `train_head.csv.dvc`. This contains `md5` hashes for both the input and output files.\n",
    "\n",
    "The contents of `train_head.csv.dvc`:\n",
    "\n",
    "```yaml\n",
    "md5: 0e1ce87d933511bce02403cd3d0ac8a8\n",
    "cmd: head train.csv > train_head.csv\n",
    "deps:\n",
    "- md5: f3eaeafb90cde88b238ebc8dfd4501c5\n",
    "  path: train.csv\n",
    "outs:\n",
    "- md5: e502cb16c02f3572bb68adadcfc50463\n",
    "  path: train_head.csv\n",
    "  cache: true\n",
    "  metric: false\n",
    "  persist: false\n",
    "```\n",
    "\n",
    "The content cache is in `FIRST_TWO_HASH_VALUES/REMAINING_VALUES` format:\n",
    "\n",
    "```\n",
    "$ ls .dvc/cache/\n",
    "a3 e5 f3\n",
    "$ ls a3\n",
    "5759d77c0a3dadb4d4253ff87ec430\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running these commands we have a repository with code managed by Git and data managed by DVC. So far so good, but it's still not reproducible (or very useful) because the repository is non-portable. The `.cache` directory is added to `.gitignore` at `dvc init` time; it's just a convenience for the targetting reuse of data files on local disk.\n",
    "\n",
    "## Using DVC with a remote\n",
    "\n",
    "To get utility out of DVC you need to configure a remote. This will allow you to `dvc push` to and `dvc pull` from the remote to get all of the data artifacts you need. DVC supports all of S3, GCS, and Azure Blob Storage.\n",
    "\n",
    "Run:\n",
    "\n",
    "```\n",
    "$ dvc remote add -d s3://spell-share/aleksey/dvc-exploration\n",
    "```\n",
    "\n",
    "This will configure this bucket and path as the default remote for this project. This is controlled by `.dvc/config`, a (`git` version controlled) file which is empty at `dvc init` time but whose contents will now be:\n",
    "\n",
    "```ini\n",
    "[core]\n",
    "    remote = spell-share\n",
    "['remote \"spell-share\"']\n",
    "    url = s3://spell-share/aleksey/dvc-exploration\n",
    "```\n",
    "\n",
    "To publish the data to collaborators you now:\n",
    "\n",
    "```\n",
    "$ dvc push\n",
    "```\n",
    "\n",
    "This flushes the contents of the `.dvc/cache` directory to S3:\n",
    "\n",
    "```\n",
    "$ aws s3 ls s3://spell-share/aleksey/dvc-exploration/\n",
    "                           PRE a3/\n",
    "                           PRE e5/\n",
    "                           PRE f3/\n",
    "```\n",
    "\n",
    "We can now reproduce the data for the repository from a clean copy of the repository:\n",
    "\n",
    "```\n",
    "$ git clone https://github.com/ResidentMario/dvc-exploration.git dvc-exploration-new\n",
    "$ cd dvc-exploration-new\n",
    "$ dvc pull\n",
    "```\n",
    "\n",
    "AFAICT this will find all of the `*.dvc` files rooted in the current directory (recursive search?), grab their `md5` fields, and `boto3` to pull them from the S3 CAS created in the `dvc push` step.\n",
    "\n",
    "This unifies all of your team's data fetch operations across all of your projects under a common API, which is very nice indeed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if you already have it in your local cache though\n",
    "\n",
    "Key observation: **DVC will skip pulling data from S3 if the file is already in the local cache**.\n",
    "\n",
    "To verify this, try the following:\n",
    "\n",
    "```\n",
    "$ cd ..; rm dc-exploration-new\n",
    "$ git clone https://github.com/ResidentMario/dvc-exploration.git dvc-exploration-new\n",
    "$ cd dvc-exploration-new\n",
    "$ cp -rf ../dvc-exploration/.dvc/cache .cache/\n",
    "```\n",
    "\n",
    "This will make a copy of a complete local cache in the new repo without one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 72\n",
      "drwxr-xr-x  8 alekseybilogur  staff   256B May 18 19:45 \u001b[1m\u001b[36m.\u001b[m\u001b[m\n",
      "drwxr-xr-x  9 alekseybilogur  staff   288B May 18 19:34 \u001b[1m\u001b[36m..\u001b[m\u001b[m\n",
      "-rw-r--r--  1 alekseybilogur  staff    37B May 18 19:33 .gitignore\n",
      "lrwxr-xr-x  1 alekseybilogur  staff    53B May 18 19:45 \u001b[35mtest.csv\u001b[m\u001b[m -> /Users/alekseybilogur/Desktop/dvc-data-files/test.csv\n",
      "-rw-r--r--  1 alekseybilogur  staff   148B May 18 19:20 test.csv.dvc\n",
      "lrwxr-xr-x  1 alekseybilogur  staff    54B May 18 19:24 \u001b[35mtrain.csv\u001b[m\u001b[m -> /Users/alekseybilogur/Desktop/dvc-data-files/train.csv\n",
      "-rw-r--r--  1 alekseybilogur  staff   149B May 18 19:20 train.csv.dvc\n",
      "-rw-r--r--  1 alekseybilogur  staff    23K May 18 19:33 train_head.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -lah ../data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DVC run command succeeded with the expected result. The symlinks are still in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwxr-xr-x   5 alekseybilogur  staff   160B May 18 19:33 \u001b[1m\u001b[36m.\u001b[m\u001b[m\n",
      "drwxr-xr-x  10 alekseybilogur  staff   320B May 18 19:33 \u001b[1m\u001b[36m..\u001b[m\u001b[m\n",
      "drwxr-xr-x   3 alekseybilogur  staff    96B May 18 19:20 \u001b[1m\u001b[36ma3\u001b[m\u001b[m\n",
      "drwxr-xr-x   3 alekseybilogur  staff    96B May 18 19:33 \u001b[1m\u001b[36me5\u001b[m\u001b[m\n",
      "drwxr-xr-x   3 alekseybilogur  staff    96B May 18 19:20 \u001b[1m\u001b[36mf3\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -lah ../.dvc/cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course the cache entry is still populated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !head ../.dvc/cache/a3/5759d77c0a3dadb4d4253ff87ec430"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment proves that DVC can target files not under its control which are symlinks.\n",
    "\n",
    "Recall that the cache is where DVC stores the copy of the dataset which it is in control of. Cache entries are files of the `./cache/TWO/MANY` format, where `TWO` is the first two digits of a content hash and `MANY` is the remainder. Files are copied (moved? the docs say \"moved\" and I should verify what the behavior here is exactly) into this directory at `dvc add` time. DVC then creates a `.gitignore` file in the target file's directory, placing the dataset out of `git` version control.\n",
    "\n",
    "From now on DVC command targeting the original path for the dataset will transparently go to the cache copy of the data instead. The original data file will appear not appear in the Git repository.\n",
    "\n",
    "This seems...kind of useless, honestly? It doesn't help me in any way because other users don't have access to my local filesystem, obviously.\n",
    "\n",
    "The more interesting part of DVC is the through-remote. DVC has remote setup, push, and pull semantics targetting object storage.\n",
    "\n",
    "I configured `s3://spell-share/aleksey/dvc-exploration` as my default remote via `dvc remote add`. I then used `dvc push` to send the files.\n",
    "\n",
    "Then after a `git clone https://github.com/ResidentMario/dvc-exploration.git dvc-exploration-new` and a `cd dvc-exploration-new` and a `dvc pull` I get the data files down from S3 safe and sound. Peachy; this is the core value prop of DVC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "\n",
    "Let's try modifying the repository that gets pulled down, overwriting the cache entry pointing into S3 with an entry pointing to a path on the local machine instead. `dvc pull` should then target this instead of S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mdata\u001b[0m                                                                \n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc list ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/train.csv\n",
      "/test.csv\n",
      "/train_head.csv\n"
     ]
    }
   ],
   "source": [
    "!cat ../data/.gitignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
